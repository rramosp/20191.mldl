{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos el dataset\n",
    "\n",
    "observa cómo convertimos la variable $y$ en **categórica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de los datos originales (1500, 785)\n",
      "(1500, 784) (1500,) (1500, 10)\n",
      "(1050, 784) (1050, 10) (450, 784) (450, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = np.loadtxt(\"data/mnist1.5k.csv\", delimiter=\",\")\n",
    "print (\"dimension de los datos originales\", mnist.shape)\n",
    "X=mnist[:,1:785]\n",
    "y=mnist[:,0]\n",
    "yc = tf.keras.utils.to_categorical(y)\n",
    "print (X.shape, y.shape, yc.shape)\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X,yc,test_size=.3)\n",
    "print (Xtr.shape, ytr.shape, Xts.shape, yts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 4. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (yc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos el modelo con  `keras`\n",
    "\n",
    "observa el número de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/.conda/envs/p37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               100500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 341,610\n",
      "Trainable params: 341,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_A():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='tanh', input_dim=784))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(500, activation='tanh'))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model\n",
    "\n",
    "model = get_model_A()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 450 samples\n",
      "WARNING:tensorflow:From /home/user/.conda/envs/p37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "1050/1050 [==============================] - 0s 390us/sample - loss: 1.3816 - acc: 0.5381 - val_loss: 0.9837 - val_acc: 0.6578\n",
      "Epoch 2/40\n",
      "1050/1050 [==============================] - 0s 146us/sample - loss: 0.7550 - acc: 0.7419 - val_loss: 0.7882 - val_acc: 0.7422\n",
      "Epoch 3/40\n",
      "1050/1050 [==============================] - 0s 147us/sample - loss: 0.5476 - acc: 0.8152 - val_loss: 0.6910 - val_acc: 0.7733\n",
      "Epoch 4/40\n",
      "1050/1050 [==============================] - 0s 145us/sample - loss: 0.4695 - acc: 0.8476 - val_loss: 0.6904 - val_acc: 0.7533\n",
      "Epoch 5/40\n",
      "1050/1050 [==============================] - 0s 140us/sample - loss: 0.4615 - acc: 0.8562 - val_loss: 0.7539 - val_acc: 0.7289\n",
      "Epoch 6/40\n",
      "1050/1050 [==============================] - 0s 153us/sample - loss: 0.4501 - acc: 0.8457 - val_loss: 0.6739 - val_acc: 0.7867\n",
      "Epoch 7/40\n",
      "1050/1050 [==============================] - 0s 144us/sample - loss: 0.4425 - acc: 0.8562 - val_loss: 0.6273 - val_acc: 0.7889\n",
      "Epoch 8/40\n",
      "1050/1050 [==============================] - 0s 155us/sample - loss: 0.4432 - acc: 0.8524 - val_loss: 0.6938 - val_acc: 0.7711\n",
      "Epoch 9/40\n",
      "1050/1050 [==============================] - 0s 148us/sample - loss: 0.4278 - acc: 0.8667 - val_loss: 0.5873 - val_acc: 0.8200\n",
      "Epoch 10/40\n",
      "1050/1050 [==============================] - 0s 142us/sample - loss: 0.3596 - acc: 0.8857 - val_loss: 0.6277 - val_acc: 0.8244\n",
      "Epoch 11/40\n",
      "1050/1050 [==============================] - 0s 152us/sample - loss: 0.3049 - acc: 0.9029 - val_loss: 0.5874 - val_acc: 0.8333\n",
      "Epoch 12/40\n",
      "1050/1050 [==============================] - 0s 149us/sample - loss: 0.3126 - acc: 0.8905 - val_loss: 0.6271 - val_acc: 0.8067\n",
      "Epoch 13/40\n",
      "1050/1050 [==============================] - 0s 148us/sample - loss: 0.3303 - acc: 0.8819 - val_loss: 0.5794 - val_acc: 0.8289\n",
      "Epoch 14/40\n",
      "1050/1050 [==============================] - 0s 145us/sample - loss: 0.2999 - acc: 0.9048 - val_loss: 0.6091 - val_acc: 0.8244\n",
      "Epoch 15/40\n",
      "1050/1050 [==============================] - 0s 143us/sample - loss: 0.2975 - acc: 0.8962 - val_loss: 0.7091 - val_acc: 0.7956\n",
      "Epoch 16/40\n",
      "1050/1050 [==============================] - 0s 144us/sample - loss: 0.2842 - acc: 0.9095 - val_loss: 0.6392 - val_acc: 0.8267\n",
      "Epoch 17/40\n",
      "1050/1050 [==============================] - 0s 143us/sample - loss: 0.2895 - acc: 0.8924 - val_loss: 0.7153 - val_acc: 0.7844\n",
      "Epoch 18/40\n",
      "1050/1050 [==============================] - 0s 143us/sample - loss: 0.2684 - acc: 0.9057 - val_loss: 0.7236 - val_acc: 0.7933\n",
      "Epoch 19/40\n",
      "1050/1050 [==============================] - 0s 150us/sample - loss: 0.2626 - acc: 0.9076 - val_loss: 0.7114 - val_acc: 0.7911\n",
      "Epoch 20/40\n",
      "1050/1050 [==============================] - 0s 148us/sample - loss: 0.2924 - acc: 0.9029 - val_loss: 0.6663 - val_acc: 0.7933\n",
      "Epoch 21/40\n",
      "1050/1050 [==============================] - 0s 142us/sample - loss: 0.2634 - acc: 0.9048 - val_loss: 0.7199 - val_acc: 0.7800\n",
      "Epoch 22/40\n",
      "1050/1050 [==============================] - 0s 137us/sample - loss: 0.2675 - acc: 0.9124 - val_loss: 0.6426 - val_acc: 0.8133\n",
      "Epoch 23/40\n",
      "1050/1050 [==============================] - 0s 140us/sample - loss: 0.2605 - acc: 0.9086 - val_loss: 0.7083 - val_acc: 0.7800\n",
      "Epoch 24/40\n",
      "1050/1050 [==============================] - 0s 142us/sample - loss: 0.2466 - acc: 0.9143 - val_loss: 0.7420 - val_acc: 0.7844\n",
      "Epoch 25/40\n",
      "1050/1050 [==============================] - 0s 145us/sample - loss: 0.2947 - acc: 0.8971 - val_loss: 0.7996 - val_acc: 0.7844\n",
      "Epoch 26/40\n",
      "1050/1050 [==============================] - 0s 146us/sample - loss: 0.2653 - acc: 0.9114 - val_loss: 0.7696 - val_acc: 0.7822\n",
      "Epoch 27/40\n",
      "1050/1050 [==============================] - 0s 140us/sample - loss: 0.2940 - acc: 0.9029 - val_loss: 0.7777 - val_acc: 0.7844\n",
      "Epoch 28/40\n",
      "1050/1050 [==============================] - 0s 139us/sample - loss: 0.2853 - acc: 0.9010 - val_loss: 0.7701 - val_acc: 0.7844\n",
      "Epoch 29/40\n",
      "1050/1050 [==============================] - 0s 138us/sample - loss: 0.3214 - acc: 0.8933 - val_loss: 0.7600 - val_acc: 0.7956\n",
      "Epoch 30/40\n",
      "1050/1050 [==============================] - 0s 142us/sample - loss: 0.3447 - acc: 0.8800 - val_loss: 0.7899 - val_acc: 0.7733\n",
      "Epoch 31/40\n",
      "1050/1050 [==============================] - 0s 144us/sample - loss: 0.2937 - acc: 0.9029 - val_loss: 0.7298 - val_acc: 0.8022\n",
      "Epoch 32/40\n",
      "1050/1050 [==============================] - 0s 148us/sample - loss: 0.3147 - acc: 0.8886 - val_loss: 0.7672 - val_acc: 0.7800\n",
      "Epoch 33/40\n",
      "1050/1050 [==============================] - 0s 137us/sample - loss: 0.2775 - acc: 0.8952 - val_loss: 0.8691 - val_acc: 0.7778\n",
      "Epoch 34/40\n",
      "1050/1050 [==============================] - 0s 135us/sample - loss: 0.2553 - acc: 0.9095 - val_loss: 0.8259 - val_acc: 0.7800\n",
      "Epoch 35/40\n",
      "1050/1050 [==============================] - 0s 139us/sample - loss: 0.2101 - acc: 0.9276 - val_loss: 0.7905 - val_acc: 0.7933\n",
      "Epoch 36/40\n",
      "1050/1050 [==============================] - 0s 142us/sample - loss: 0.2316 - acc: 0.9248 - val_loss: 0.8015 - val_acc: 0.7756\n",
      "Epoch 37/40\n",
      "1050/1050 [==============================] - 0s 139us/sample - loss: 0.2416 - acc: 0.9152 - val_loss: 0.8484 - val_acc: 0.7711\n",
      "Epoch 38/40\n",
      "1050/1050 [==============================] - 0s 138us/sample - loss: 0.2023 - acc: 0.9324 - val_loss: 0.7718 - val_acc: 0.7644\n",
      "Epoch 39/40\n",
      "1050/1050 [==============================] - 0s 136us/sample - loss: 0.2537 - acc: 0.9076 - val_loss: 0.9353 - val_acc: 0.7400\n",
      "Epoch 40/40\n",
      "1050/1050 [==============================] - 0s 142us/sample - loss: 0.2750 - acc: 0.9076 - val_loss: 0.8894 - val_acc: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f16e16e1b00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr, ytr, epochs=40, batch_size=64, validation_data=(Xts, yts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadimos capas de regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/.conda/envs/p37/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               100500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 341,610\n",
      "Trainable params: 341,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_B():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='tanh', input_dim=784))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(500, activation='tanh'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model\n",
    "\n",
    "model = get_model_B()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 450 samples\n",
      "Epoch 1/50\n",
      "1050/1050 [==============================] - 0s 426us/sample - loss: 1.8346 - acc: 0.3695 - val_loss: 1.0662 - val_acc: 0.6644\n",
      "Epoch 2/50\n",
      "1050/1050 [==============================] - 0s 156us/sample - loss: 1.1432 - acc: 0.6105 - val_loss: 0.8758 - val_acc: 0.7400\n",
      "Epoch 3/50\n",
      "1050/1050 [==============================] - 0s 156us/sample - loss: 1.0049 - acc: 0.6543 - val_loss: 0.8324 - val_acc: 0.7244\n",
      "Epoch 4/50\n",
      "1050/1050 [==============================] - 0s 156us/sample - loss: 0.8927 - acc: 0.7000 - val_loss: 0.7543 - val_acc: 0.7578\n",
      "Epoch 5/50\n",
      "1050/1050 [==============================] - 0s 156us/sample - loss: 0.8804 - acc: 0.7010 - val_loss: 0.7093 - val_acc: 0.7644\n",
      "Epoch 6/50\n",
      "1050/1050 [==============================] - 0s 160us/sample - loss: 0.8668 - acc: 0.7076 - val_loss: 0.6970 - val_acc: 0.7756\n",
      "Epoch 7/50\n",
      "1050/1050 [==============================] - 0s 166us/sample - loss: 0.8102 - acc: 0.7419 - val_loss: 0.7081 - val_acc: 0.7822\n",
      "Epoch 8/50\n",
      "1050/1050 [==============================] - 0s 155us/sample - loss: 0.7634 - acc: 0.7419 - val_loss: 0.7034 - val_acc: 0.7778\n",
      "Epoch 9/50\n",
      "1050/1050 [==============================] - 0s 155us/sample - loss: 0.7055 - acc: 0.7705 - val_loss: 0.7079 - val_acc: 0.7867\n",
      "Epoch 10/50\n",
      "1050/1050 [==============================] - 0s 158us/sample - loss: 0.7216 - acc: 0.7543 - val_loss: 0.7748 - val_acc: 0.7422\n",
      "Epoch 11/50\n",
      "1050/1050 [==============================] - 0s 155us/sample - loss: 0.7140 - acc: 0.7571 - val_loss: 0.7008 - val_acc: 0.7822\n",
      "Epoch 12/50\n",
      "1050/1050 [==============================] - 0s 152us/sample - loss: 0.7018 - acc: 0.7714 - val_loss: 0.6742 - val_acc: 0.7800\n",
      "Epoch 13/50\n",
      "1050/1050 [==============================] - 0s 162us/sample - loss: 0.6589 - acc: 0.7838 - val_loss: 0.6668 - val_acc: 0.8044\n",
      "Epoch 14/50\n",
      "1050/1050 [==============================] - 0s 191us/sample - loss: 0.7048 - acc: 0.7695 - val_loss: 0.6509 - val_acc: 0.8067\n",
      "Epoch 15/50\n",
      "1050/1050 [==============================] - 0s 169us/sample - loss: 0.6752 - acc: 0.7771 - val_loss: 0.6656 - val_acc: 0.7778\n",
      "Epoch 16/50\n",
      "1050/1050 [==============================] - 0s 167us/sample - loss: 0.6276 - acc: 0.7848 - val_loss: 0.6019 - val_acc: 0.8089\n",
      "Epoch 17/50\n",
      "1050/1050 [==============================] - 0s 183us/sample - loss: 0.6182 - acc: 0.7952 - val_loss: 0.5913 - val_acc: 0.8156\n",
      "Epoch 18/50\n",
      "1050/1050 [==============================] - 0s 201us/sample - loss: 0.6398 - acc: 0.7724 - val_loss: 0.5995 - val_acc: 0.8244\n",
      "Epoch 19/50\n",
      "1050/1050 [==============================] - 0s 151us/sample - loss: 0.6561 - acc: 0.7771 - val_loss: 0.6022 - val_acc: 0.8089\n",
      "Epoch 20/50\n",
      "1050/1050 [==============================] - 0s 157us/sample - loss: 0.6406 - acc: 0.7895 - val_loss: 0.6848 - val_acc: 0.7756\n",
      "Epoch 21/50\n",
      "1050/1050 [==============================] - 0s 159us/sample - loss: 0.6286 - acc: 0.7971 - val_loss: 0.6912 - val_acc: 0.8044\n",
      "Epoch 22/50\n",
      "1050/1050 [==============================] - 0s 163us/sample - loss: 0.6373 - acc: 0.7886 - val_loss: 0.6178 - val_acc: 0.8378\n",
      "Epoch 23/50\n",
      "1050/1050 [==============================] - 0s 173us/sample - loss: 0.6232 - acc: 0.7933 - val_loss: 0.6814 - val_acc: 0.8178\n",
      "Epoch 24/50\n",
      "1050/1050 [==============================] - 0s 168us/sample - loss: 0.6317 - acc: 0.7857 - val_loss: 0.5954 - val_acc: 0.8178\n",
      "Epoch 25/50\n",
      "1050/1050 [==============================] - 0s 163us/sample - loss: 0.5970 - acc: 0.7933 - val_loss: 0.5924 - val_acc: 0.8156\n",
      "Epoch 26/50\n",
      "1050/1050 [==============================] - 0s 205us/sample - loss: 0.5748 - acc: 0.8124 - val_loss: 0.6082 - val_acc: 0.8111\n",
      "Epoch 27/50\n",
      "1050/1050 [==============================] - 0s 174us/sample - loss: 0.5807 - acc: 0.8048 - val_loss: 0.6150 - val_acc: 0.8089\n",
      "Epoch 28/50\n",
      "1050/1050 [==============================] - 0s 170us/sample - loss: 0.5045 - acc: 0.8181 - val_loss: 0.6636 - val_acc: 0.8200\n",
      "Epoch 29/50\n",
      "1050/1050 [==============================] - 0s 180us/sample - loss: 0.5553 - acc: 0.8048 - val_loss: 0.5996 - val_acc: 0.8267\n",
      "Epoch 30/50\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5898 - acc: 0.8095 - val_loss: 0.6137 - val_acc: 0.8000\n",
      "Epoch 31/50\n",
      "1050/1050 [==============================] - 0s 167us/sample - loss: 0.5501 - acc: 0.8133 - val_loss: 0.5679 - val_acc: 0.8200\n",
      "Epoch 32/50\n",
      "1050/1050 [==============================] - 0s 161us/sample - loss: 0.5026 - acc: 0.8219 - val_loss: 0.5974 - val_acc: 0.8200\n",
      "Epoch 33/50\n",
      "1050/1050 [==============================] - 0s 172us/sample - loss: 0.5731 - acc: 0.8162 - val_loss: 0.5381 - val_acc: 0.8444\n",
      "Epoch 34/50\n",
      "1050/1050 [==============================] - 0s 162us/sample - loss: 0.5396 - acc: 0.8114 - val_loss: 0.5756 - val_acc: 0.8356\n",
      "Epoch 35/50\n",
      "1050/1050 [==============================] - 0s 165us/sample - loss: 0.5761 - acc: 0.8152 - val_loss: 0.5759 - val_acc: 0.8311\n",
      "Epoch 36/50\n",
      "1050/1050 [==============================] - 0s 183us/sample - loss: 0.5550 - acc: 0.8190 - val_loss: 0.6434 - val_acc: 0.8267\n",
      "Epoch 37/50\n",
      "1050/1050 [==============================] - 0s 199us/sample - loss: 0.5454 - acc: 0.8229 - val_loss: 0.6284 - val_acc: 0.8156\n",
      "Epoch 38/50\n",
      "1050/1050 [==============================] - 0s 201us/sample - loss: 0.5122 - acc: 0.8314 - val_loss: 0.5638 - val_acc: 0.8333\n",
      "Epoch 39/50\n",
      "1050/1050 [==============================] - 0s 222us/sample - loss: 0.5973 - acc: 0.8067 - val_loss: 0.5907 - val_acc: 0.8267\n",
      "Epoch 40/50\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.5457 - acc: 0.8210 - val_loss: 0.5788 - val_acc: 0.8422\n",
      "Epoch 41/50\n",
      "1050/1050 [==============================] - 0s 336us/sample - loss: 0.5401 - acc: 0.8143 - val_loss: 0.6607 - val_acc: 0.8378\n",
      "Epoch 42/50\n",
      "1050/1050 [==============================] - 0s 287us/sample - loss: 0.5402 - acc: 0.8267 - val_loss: 0.6003 - val_acc: 0.8244\n",
      "Epoch 43/50\n",
      "1050/1050 [==============================] - 0s 372us/sample - loss: 0.5613 - acc: 0.8267 - val_loss: 0.5840 - val_acc: 0.8311\n",
      "Epoch 44/50\n",
      "1050/1050 [==============================] - 0s 378us/sample - loss: 0.5909 - acc: 0.7981 - val_loss: 0.6542 - val_acc: 0.8200\n",
      "Epoch 45/50\n",
      "1050/1050 [==============================] - 0s 343us/sample - loss: 0.6501 - acc: 0.7895 - val_loss: 0.6429 - val_acc: 0.8067\n",
      "Epoch 46/50\n",
      "1050/1050 [==============================] - 0s 335us/sample - loss: 0.6807 - acc: 0.7657 - val_loss: 0.6612 - val_acc: 0.7978\n",
      "Epoch 47/50\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.6818 - acc: 0.7667 - val_loss: 0.6704 - val_acc: 0.8067\n",
      "Epoch 48/50\n",
      "1050/1050 [==============================] - 0s 311us/sample - loss: 0.6145 - acc: 0.7905 - val_loss: 0.5644 - val_acc: 0.8356\n",
      "Epoch 49/50\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.6080 - acc: 0.8000 - val_loss: 0.7164 - val_acc: 0.7844\n",
      "Epoch 50/50\n",
      "1050/1050 [==============================] - 0s 385us/sample - loss: 0.5658 - acc: 0.8171 - val_loss: 0.6253 - val_acc: 0.8111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f16dc04eac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr, ytr,\n",
    "         batch_size=64,\n",
    "         epochs=50,\n",
    "         validation_data=(Xts, yts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
